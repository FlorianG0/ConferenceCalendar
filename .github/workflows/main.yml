name: Crawl and Deploy Conference Calendar

on:
  schedule:
    # UTC times: 05:00 and 17:00 UTC (â‰ˆ 06/18 CET, 07/19 CEST)
    - cron: "0 5,17 * * *"
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "crawl-pages"
  cancel-in-progress: false

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (main)
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Crawl deadline pages
        env:
          # Optional: SMTP secrets, only if your script sends emails.
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
          MAIL_TO: ${{ secrets.MAIL_TO }}
          MAIL_FROM: ${{ secrets.MAIL_FROM }}
        run: python scripts/crawl_deadlines.py

      - name: Commit crawler updates
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add data/conferences.json data/deadline_history.json public/group-deadlines.ics site/ || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "chore: update conference deadlines"

          # Rebase in case something changed on main while we ran
          git pull --rebase origin main
          git push origin HEAD:main

  deploy:
    needs: crawl
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      # CRITICAL: checkout latest main, not the workflow trigger SHA
      - name: Checkout latest main
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 1

      - name: Build Pages artifact
        run: |
          rm -rf dist
          mkdir -p dist/data

          # Serve website root
          cp site/index.html dist/index.html

          # Data for the website
          cp data/conferences.json dist/data/conferences.json
          cp data/deadline_history.json dist/data/deadline_history.json || true

          # Optional: publish ICS too
          if [ -f public/group-deadlines.ics ]; then
            cp public/group-deadlines.ics dist/group-deadlines.ics
          fi

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: dist

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
